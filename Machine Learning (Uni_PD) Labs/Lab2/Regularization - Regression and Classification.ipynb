{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Regression on House Pricing Dataset\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "[https://www.kaggle.com/harlfoxem/housesalesprediction]\n",
    "\n",
    "For each house we know 19 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, remove data samples/points with missing values (NaN) and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input and output data. We want to predict the price by using othr features (other than id) as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data = df.values\n",
    "#N = number of input samples\n",
    "N = 3164\n",
    "Y = Data[:N,2]\n",
    "X = Data[:N,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Split the data into training a training set of $N_{tr}$ samples and a test set of $N_{te}:=N-N_{tr}$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into train (50 samples) and test data (the rest)\n",
    "Ntr = 50\n",
    "Nte = N - Ntr\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#PUT YOUR NUMERO DI MATRICOLA BELOW!\n",
    "numero_di_matricola = 1115\n",
    "\n",
    "Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=Nte/N, random_state=numero_di_matricola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtr)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xte = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-Squares Solution\n",
    "\n",
    "The routine LinearRegression.score(X,y) computes the *Coefficient of determination* $R^2$, defined as:\n",
    "\n",
    "$$R^2 = 1- \\frac{RSS}{TSS}$$\n",
    "\n",
    "where $RSS$ is the *Residual Sum of Squares* and $TSS$ is the *Total Sum of Square*. Denoting with $\\hat{y}_i$ the $i$-th predicted output values, they are so defined:\n",
    "\n",
    "\\begin{align*}\n",
    "RSS &= \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\\\\\n",
    "TSS &= \\sum_{i=1}^N (y_i -\\bar{y}_i)^2, \\qquad \\qquad \\bar{y}_i=\\frac{1}{N} \\sum_{i=1}^N y_i\n",
    "\\end{align*}\n",
    "\n",
    "In this notebook we will mostly use the coefficient of determination $R^2$ (instead of the RSS) as a measure to compare models and choose tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1\n",
    "\n",
    "Answer the following: are we interested in models with low $R^2$ or high $R^2$? Why? (max 5 lines)\n",
    "\n",
    "Now compute the Least-Squares estimate using LinearRegression() in Scikit-learn, and print the corresponding score in training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least-Squares\n",
    "from sklearn import linear_model as lm\n",
    "#OLS is the linear regression model\n",
    "OLS = ????\n",
    "\n",
    "#fit the model on training data\n",
    "????\n",
    "\n",
    "#obtain predictions on training data\n",
    "Yhat_tr = ????\n",
    "\n",
    "#coefficients from the model\n",
    "b_LS = np.hstack((OLS.intercept_, OLS.coef_))\n",
    "\n",
    "print \"Coefficient of determination on training data:\", ????\n",
    "print \"Coefficient of determination on test data:\", ????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2\n",
    "\n",
    "Compute the confidence interval for each coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least-Squares: Confidence Intervals\n",
    "from scipy.stats import t\n",
    "\n",
    "#add the column of all ones for the intercept of the model\n",
    "Xtr_intercept = np.hstack((np.ones((Xtr.shape[0],1)), Xtr))\n",
    "\n",
    "#alpha for confidence intervals\n",
    "alpha = 0.05\n",
    "\n",
    "#quantile from t-student distribution\n",
    "tperc = ????\n",
    "sigma2 = ????\n",
    "\n",
    "R = ????\n",
    "\n",
    "Ri = ????\n",
    "v = ????\n",
    "Delta = ????\n",
    "CI = np.transpose(np.vstack((b_LS,b_LS))) + np.transpose(np.vstack((-Delta,+Delta) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the LS coefficients and their confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot confidence intervals\n",
    "plt.figure(1)\n",
    "plt.plot(b_LS[1:], 'r', marker='o', ms=7.0)\n",
    "plt.plot(CI[1:,0], 'b--')\n",
    "plt.plot(CI[1:,1], 'b--')\n",
    "plt.plot(np.zeros(b_LS.shape[0],), 'k', linewidth=2.0)\n",
    "plt.xlabel('Coefficient Index')\n",
    "plt.ylabel('LS Coefficient')\n",
    "plt.title('Coefficients and Confidence Sets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: based on the results above, if you had to choose at most 5 features for a linear regression model, which ones would you choose? Why?\n",
    "\n",
    "### TODO 3\n",
    "Answer the question above (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best-Subset Selection\n",
    "\n",
    "Split the training data into a training and validation dataset. For $k$ going from 1 to $n_{sub}=4$:\n",
    "1. Compute the LS estimate using all the possible subsets of $k$ features\n",
    "2. Compute the prediction error on the validation dataset\n",
    "\n",
    "Choose the subset of $k^*$ features giving the lowest validation error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "Xtr_cv, Xva_cv, Ytr_cv, Yva_cv = train_test_split(Xtr, Ytr, test_size=0.33)\n",
    "nsub = 5 # Xtr.shape[1]\n",
    "features_idx_dict = {}\n",
    "validation_err_dict = {}\n",
    "validation_err_min = np.zeros(nsub,)\n",
    "validation_err_min_idx = np.zeros(nsub, dtype=np.int64)\n",
    "for k in range(1,nsub+1):\n",
    "    features_idx = list(itertools.combinations(range(Xtr.shape[1]),k))\n",
    "    validation_error = np.zeros(len(features_idx),)\n",
    "    for j in range(len(features_idx)):\n",
    "        OLS_subset = lm.LinearRegression()\n",
    "        OLS_subset.fit(Xtr_cv[:,features_idx[j]], Ytr_cv)\n",
    "        validation_error[j] = 1 - OLS_subset.score(Xva_cv[:,features_idx[j]], Yva_cv)\n",
    "    validation_err_min[k-1] = np.min(validation_error)    \n",
    "    validation_err_min_idx[k-1] = np.argmin(validation_error)\n",
    "    features_idx_dict.update({k: features_idx})\n",
    "    validation_err_dict.update({k: validation_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the validation error as a function of the number of retained features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(2)\n",
    "for k in range(1,nsub+1):\n",
    "    plt.scatter(k*np.ones(validation_err_dict[k].shape), validation_err_dict[k], color='k', alpha=0.5)\n",
    "    #plt.scatter(k, validation_err_min[k-1], color='r', alpha=0.8)\n",
    "    if k > 1:\n",
    "        plt.plot([k-1, k], [validation_err_min[k-2], validation_err_min[k-1]], color='r',marker='o', \n",
    "            markeredgecolor='k', markerfacecolor = 'r', markersize = 10)\n",
    "plt.xlabel('Number of retained features')\n",
    "plt.ylabel('RSS/TSS')\n",
    "plt.title('Best-Subset Selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the LS estimate using the selected subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4: pick the number of features for the best subset according to figure above, learn the model on the entire training data, and compute score on training and on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OLS_best_subset = lm.LinearRegression()\n",
    "\n",
    "# now pick the number of features according to best subset\n",
    "opt_num_features = ????\n",
    "\n",
    "#opt_features_idx contains the indices of the features from best subset\n",
    "opt_features_idx = features_idx_dict[opt_num_features][validation_err_min_idx[opt_num_features - 1]]\n",
    "\n",
    "#let's print the indices of the features from best subset\n",
    "print opt_features_idx\n",
    "\n",
    "#fit the best subset on the entire training set\n",
    "????\n",
    "\n",
    "#print the coefficient of determination on training and on test data\n",
    "print \"Coefficient of determination on training data:\", ????\n",
    "print \"Coefficient of determination on test data:\", ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: do the features from best subset selection correspond to the ones you would have chosen based on confidence intervals for the linear regression coefficients? Comment (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "### TODO 6: Shrinkage Evaluation\n",
    "\n",
    "Compute the ridge regression coefficients on the training data (write the formula manually) using different values of the regularization parameter $\\lambda$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the values of lambda that you are going to use\n",
    "lam_values = np.logspace(0, 4, 300)\n",
    "\n",
    "#ridge_coeff will contain the solutions; note that we include \\beta_0 in the model\n",
    "ridge_coeff = np.zeros((Xtr_intercept.shape[1], len(lam_values)))\n",
    "\n",
    "#norm will contain the norm of the solutions\n",
    "norm_ridge_coeff = np.zeros(len(lam_values),)\n",
    "\n",
    "for i in range(len(lam_values)):\n",
    "    ridge_coeff[:,i] = ????\n",
    "    norm_ridge_coeff[i] = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the norm of the estimated coefficient vector vs the regularization parameter $\\lambda$. In this way you will be able to evaluate the coefficients shrinkage achieved through ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.xscale('log')\n",
    "plt.plot(lam_values, norm_ridge_coeff/Xtr_intercept.shape[1])\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Coefficients norm')\n",
    "plt.title('Average norm of the Ridge Regression coefficients vs Regularization Parameter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 7: explain the results shown in the figure above (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: Use k-fold Cross-Validation to fix the regularization parameter\n",
    "\n",
    "Use the scikit-learn built-in routine *Ridge* (from the *linear_regression* package) to compute the ridge regression coefficients.\n",
    "\n",
    "Use *KFold* from *sklearn.cross_validation* to split the data into the desired number of folds.\n",
    "\n",
    "The pick $lam\\_opt$ to be the chosen value for the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "num_folds = 5\n",
    "kf = KFold(n=Ntr, n_folds=num_folds)\n",
    "\n",
    "#loss_ridge_kfold will contain the value of the loss\n",
    "loss_ridge_kfold = np.zeros(len(lam_values),)\n",
    "\n",
    "for i in range(len(lam_values)):\n",
    "    \n",
    "    #define a ridge regressor using Ridge() for the i-th value of lam_values\n",
    "    ridge_kfold = lm.Ridge(alpha=lam_values[i])\n",
    "    for train_index, validation_index in kf:\n",
    "        Xtr_kfold, Xva_kfold = Xtr[train_index], Xtr[validation_index]\n",
    "        Ytr_kfold, Yva_kfold = Ytr[train_index], Ytr[validation_index]\n",
    "        \n",
    "        #learn the model using the training data from the k-fold\n",
    "        ????\n",
    "        \n",
    "        #compute the loss using the validation data from the k-fold\n",
    "        ????\n",
    "\n",
    "loss_ridge_kfold /= Ntr\n",
    "\n",
    "#choose the regularization parameter that minimizes the loss\n",
    "lam_opt = ????\n",
    "print \"Best value of the regularization parameter:\", lam_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Cross-Validation estimate of the prediction error as a function of the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.xscale('log')\n",
    "plt.plot(lam_values, loss_ridge_kfold, color='b')\n",
    "plt.scatter(lam_opt, loss_ridge_kfold[np.argmin(loss_ridge_kfold)], color='b', marker='o', linewidths=5)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.title('Ridge Regression: choice of regularization parameter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 9: now estimate the ridge regression coefficients using all the training data and the optimal regularization parameter (chosen at previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimate Ridge Regression Coefficients with all data for the the optimal value lam_opt of the regularization paramter\n",
    "\n",
    "#define the model using the optimal value lam_opt\n",
    "????\n",
    "#fit using the training data\n",
    "????\n",
    "\n",
    "print \"Coefficient of determination on training data:\", ????\n",
    "print \"Coefficient of determination on test data:\", ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comapre the LS and the ridge regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare LS and ridge coefficients\n",
    "ind = np.arange(1,len(OLS.coef_)+1)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, OLS.coef_, width, color='r')\n",
    "rects2 = ax.bar(ind + width, ridge_reg.coef_, width, color='y')\n",
    "ax.legend((rects1[0], rects2[0]), ('LS', 'Ridge'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('LS and Ridge Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: comment on the comparison among the LS and Ridge Regression coefficients (max 5 lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "\n",
    "Use the routine *lasso_path* from *sklearn.linear_regression* to compute the \"lasso path\" for different values of the regularization parameter $\\lambda$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# To pass a specific range of lambda values\n",
    "#lasso_lams, lasso_coefs, _ = lasso_path(Xtr, Ytr, alphas=lam_values)  \n",
    "\n",
    "# If no value is passed, the routine automatically select a range of values \n",
    "lasso_lams, lasso_coefs, _ = lasso_path(Xtr, Ytr) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the sparsity in the estimated coefficients as a function of the regularization parameter $\\lambda$: to this purpose, compute the number of non-zero entries in the estimated coefficient vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_coef_norm = np.zeros(len(lasso_lams),)\n",
    "\n",
    "for i in range(len(lasso_lams)):\n",
    "    l0_coef_norm[i] = sum(lasso_coefs[:,i]!=0)\n",
    "\n",
    "\n",
    "plt.figure(6)\n",
    "plt.plot(lasso_lams, l0_coef_norm, marker='o', markersize=5)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Number of non-zero coefficients')\n",
    "plt.title('Sparsity Degree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 11: explain the results in the figure above (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 12: Use k-fold Cross-Validation to fix the regularization parameter\n",
    "\n",
    "Use the routine *LassoCV* from the package *sklearn.linear_regression* to fix the regularization parameter $\\lambda$ throug k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use LassoCV passing num_folds for the number of folds in CV\n",
    "lasso_kfold = ????\n",
    "\n",
    "#fit using the training set\n",
    "????\n",
    "\n",
    "print \"Total number of coefficients:\", len(lasso_kfold.coef_)\n",
    "print \"Number of non-zero coefficients:\", sum(lasso_kfold.coef_ != 0)\n",
    "print \"Best value of regularization parameter:\", lasso_kfold.alpha_\n",
    "loss_lasso_kfold = np.sum(lasso_kfold.mse_path_, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 13: Plot the Cross-Validation estimate of the prediction error  as a function of the regularization parameter $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(7)\n",
    "plt.xscale('log')\n",
    "\n",
    "#plot the lasso k-fold loss as a function of the lasso_kfold.alphas_\n",
    "????\n",
    "\n",
    "#this plots the best value of the regularization parameter\n",
    "plt.scatter(lasso_kfold.alpha_, loss_lasso_kfold[np.where(lasso_kfold.alphas_ == lasso_kfold.alpha_)], \n",
    "    color='b', marker='o', linewidths=5)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.title('Lasso: choice of regularization parameter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 14: describe the results in the figure above and its relation to the best lambda chosen by CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 15: Now estimate the LASSO regression coefficients using all the training data and the optimal regularization parameter (chosen through k-fold cross-validation).\n",
    "\n",
    "Use the routine *lasso* from *sklearn.linear_regression* to do it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define a lasso model with Lasso() using the best value of the regularization parameter\n",
    "lasso_reg = ????\n",
    "#fit the model using the entire training set\n",
    "????\n",
    "\n",
    "print \"Coefficient of determination on training data:\", ????\n",
    "print \"Coefficient of determination on test data:\", ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare LS, Ridge and Lasso coefficients\n",
    "\n",
    "Use a bar plot to compare the estimated coefficients by means of these three estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.arange(1,len(OLS.coef_)+1)  # the x locations for the groups\n",
    "width = 0.25       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, OLS.coef_, width, color='r')\n",
    "rects2 = ax.bar(ind + width, ridge_reg.coef_, width, color='y')\n",
    "rects3 = ax.bar(ind + 2*width, lasso_reg.coef_, width, color='g')\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('LS', 'Ridge', 'Lasso'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('LS, Ridge and Lasso Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 16: how do coefficient from the Lasso model compare to LS and Ridge Regression? (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Coefficient of determination of LS on test data:\", OLS.score(Xte,Yte)\n",
    "print \"Coefficient of determination of LS (with subset selection) on test data:\", OLS_best_subset.score(Xte[:,opt_features_idx],Yte)\n",
    "print \"Coefficient of determination of Ridge Regression on test data:\", ridge_reg.score(Xte,Yte)\n",
    "print \"Coefficient of determination of LASSO on test data:\", lasso_reg.score(Xte,Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 17: comment and compare the results obtained by the different methods (max 10 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 18: use different data size\n",
    "\n",
    "Perform the same estimation procedures using different more points on the training data, that is fix Ntr = 100. You can simply copy and paste the code above into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put in this cell the code to do the same analysis as before but with Ntr=100\n",
    "\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 19: how do the results change with Ntr=100? (max 10 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Classification on Titanic Dataset\n",
    "\n",
    "We are going to use a dataset from a Kaggle competition (https://www.kaggle.com/c/titanic/data)\n",
    " \n",
    "### Dataset description\n",
    "\n",
    ">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.  This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    ">One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.  Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    ">In this contest, we ask you to complete the analysis of what sorts of people were likely to survive. \n",
    "\n",
    "[From the competition [homepage](http://www.kaggle.com/c/titanic-gettingStarted).]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"titanicData.csv\") \n",
    "df = df.drop(['Ticket','Cabin','Name'], axis=1)\n",
    "# Remove missing values\n",
    "df = df.dropna() \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data matrices: many of the features (columns of indices 0,1,3,4,6 in Xcat below) are categorical, so we first encode them with integers with LabelEncoder() and then obtain the indicator variables with OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = df.values\n",
    "Xcat = Data[:,2:]\n",
    "Y = Data[:,1]\n",
    "n = Xcat.shape[1]  # number of features\n",
    "\n",
    "num_samples = Xcat.shape[0]\n",
    "\n",
    "#now encode categorical variables using integers and one-hot-encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "#transform first column in integers; no need to use one hot encoder since it\n",
    "#has only 2 values\n",
    "\n",
    "X = onehot_encoder.fit_transform(Xcat[:,0].reshape(-1,1)).toarray()\n",
    "\n",
    "#repeat for the other categorical input variables\n",
    "\n",
    "index_categorical = [1,3,4,6]\n",
    "\n",
    "for i in range(1,7):\n",
    "    if i in index_categorical:\n",
    "        X_tmp = label_encoder.fit_transform(Xcat[:,i])\n",
    "        X_tmp = X_tmp.reshape(X_tmp.shape[0],1)\n",
    "        X_tmp = onehot_encoder.fit_transform(X_tmp[:,0].reshape(-1,1)).toarray()\n",
    "        X = np.hstack((X,X_tmp))\n",
    "    else:\n",
    "        X_tmp = Xcat[:,i]\n",
    "        X_tmp = X_tmp.reshape(X_tmp.shape[0],1)\n",
    "        X = np.hstack((X,X_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The class labels are already 0-1, so we can use them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename the class labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "K = max(Y) + 1 # number of classes\n",
    "\n",
    "print \"Number of classes: \"+str(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $N$ total data points, keep $N_{tr}$ data points as data for training and validation and $N_{te}:=N-N_{tr}$ as test data. Splitting is random, use as seed your ``numero di matricola'' (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "N = np.shape(X)[0]\n",
    "\n",
    "#put here your ``numero di matricola''\n",
    "Numero_di_Matricola = 11 \n",
    "\n",
    "Ntrain = 50  # use 50 samples for training + validation...\n",
    "Ntest = N-Ntrain # and the rest for testing\n",
    "\n",
    "Xtr, Xtest, Ytr, Ytest = train_test_split(X, Y, test_size=Ntest/N, random_state = Numero_di_Matricola)\n",
    "\n",
    "Ntr = Xtr.shape[0]\n",
    "Ntest = Xtest.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design matrix is standardized to have zero-mean and unit variance (columnwise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize the Features Matrix\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xtest = scaler.transform(Xtest)  # use the same transformation on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Logistic Regression\n",
    "\n",
    "We now perform logistic regression using the function provided by Scikit-learn.\n",
    "\n",
    "Note: as provided by Scikit-learn, logistic regression is always implemented using regularization. However, the impact of regularization can be dampened to have almost no regularization by changing the parameter $C$. In particular, using a very high value of $C$ reduces the impact from regularization. ($C$ is the inverse of the regularization parameter $\\lambda$ - see TODO 4.)\n",
    "\n",
    "Note that the intercept is estimated in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# define a logistic regression model with very high C parameter -> low impact from regularization\n",
    "reg = linear_model.LogisticRegression(C=100000000, solver='newton-cg')\n",
    "\n",
    "#fit the model on training data\n",
    "reg.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the logistic regression function in Scikit-learn has many optional parameters. Read the documentation to understand what they do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 1\n",
    "### Examine coefficients from Logistic Regression (by print and plotting them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print the coefficients from the logistic regression model.\n",
    "print ????\n",
    "\n",
    "# Plot the coefficients\n",
    "reg_coef = reg.coef_.reshape(reg.coef_.shape[1],)\n",
    "plt.figure()\n",
    "ind = np.arange(1,len(reg_coef)+1)  # the x locations for the groups\n",
    "width = 0.45       # the width of the bars\n",
    "plt.bar(ind, reg_coef, width, color='r')\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 2\n",
    "\n",
    "### Questions: How many coefficients do you get? Why? How many of them are equal to 0? (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "### Predict labels on training and validation\n",
    "\n",
    "- Compute the predicted labels on training and validation data using reg.predict\n",
    " - Evaluate the accuracy using metrics.accuracy_score from scikit-learn (it returns the percentage of data correctly classified).\n",
    " - Evaluate the score used by logistic regression on training and validation data using metrics.accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#prediction on training data\n",
    "Yhat_tr_LR = ????\n",
    "\n",
    "#prediction on test data\n",
    "Yhat_test_LR = ????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn for training dataset\n",
    "print \"Training Accuracy:\", 100*????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn for test dataset\n",
    "print \"Test Accuracy:\", 100*????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 4\n",
    "### Use L2 regularized logistic regression with cross-validation\n",
    "\n",
    "We perform the L2 regularization for different values of the regularization parameter $C$, and use the Scikit-learn function to perform cross-validation (CV).\n",
    "\n",
    "In L2 regularized logistic regression, the following L2 regularization term is subtracted to the log-likelihood.\n",
    "\n",
    "$$\n",
    "    \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    "where $\\lambda >0 $ is the complexity or regularization parameter. Note that the term above is *subtracted* since for logistic regression we want to maximize the log-likelihood.\n",
    "\n",
    "The parameter $C$ used by Scikit learn corresponds to the inverse of $\\lambda$, that is $C = \\frac{1}{\\lambda}$.\n",
    "\n",
    "Note: the CV in Scikit-learn is by default a *stratified* CV, that means that data is split into train-validation while maintaining the proportion of different classes in each fold.\n",
    "\n",
    "In the code below:\n",
    "- use LogisticRegressionCV() to select the best value of C with a 10-fold CV with L2 penalty;\n",
    "- use LogisticRegression() to learn the best model for the best C with L2 penalty on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the model using LogisticRegressionCV passing an appropriate solver, cv value, and choice of penalty\n",
    "regL2 = ????\n",
    "\n",
    "#fit the model on training data\n",
    "????\n",
    "\n",
    "#print the best C\n",
    "print ????\n",
    "\n",
    "#define the model using the best C and an appropriate solver\n",
    "regL2_final = ????\n",
    "\n",
    "#fit the model using the best C on the entire training set\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: print and plot the coefficients from logistic regression and the regularized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print the coefficients from logistic regression\n",
    "print ????\n",
    "\n",
    "#print the coefficients from L2 regularized logistic regression\n",
    "print ????\n",
    "\n",
    "\n",
    "# Plot the coefficients\n",
    "regL2_final_coef = regL2_final.coef_.reshape(regL2_final.coef_.shape[1],)\n",
    "ind = np.arange(1,len(reg_coef)+1)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects1 = ax.bar(ind, reg_coef, width, color='r')\n",
    "rects2 = ax.bar(ind + width, regL2_final_coef, width, color='y')\n",
    "ax.legend((rects1[0], rects2[0]), ('Log Regr', 'Log Regr + L2 Regul'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients: Standard and Regularized Version')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 6: how do the coefficients from L2 regularization compare to the ones from logistic regression? (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 7: obtain classification accuracy on training and test data for the L2 regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now get training and test error and print training and test accuracy\n",
    "\n",
    "# predictions on training data \n",
    "Yhat_tr_LR_L2 = ????\n",
    "\n",
    "# predictions on test data \n",
    "Yhat_test_LR_L2 = ????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn on training data\n",
    "print \"Training Accuracy:\", 100*????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn on test data\n",
    "print \"Test Accuracy:\",100*????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: how does accuracy compare to logistic regression? Comment (max 5 lines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 9: Use L1 regularized logistic regression with cross-validation\n",
    "\n",
    "We perform the L1 regularization for different values of the regularization parameter $C$, and use the Scikit-learn function to perform cross-validation (CV).\n",
    "\n",
    "In L1 regularized logistic regression, the following L1 regularization term is added to the loss:\n",
    "\n",
    "$$\n",
    "    \\lambda \\sum_{j=1}^p |\\beta_j|\n",
    "$$\n",
    "\n",
    "where $\\lambda >0 $ is the complexity or regularization parameter. Note that the term above is *subtracted* since for logistic regression we want to maximize the log-likelihood.\n",
    "\n",
    "The parameter $C$ used by Scikit learn corresponds to the inverse of $\\lambda$, that is $C = \\frac{1}{\\lambda}$.\n",
    "\n",
    "Note: the CV in Scikit-learn is by default a *stratified* CV, that means that data is split into train-validation while maintaining the proportion of different classes in each fold.\n",
    "\n",
    "In the code below:\n",
    "- use LogisticRegressionCV() to select the best value of C with a 10-fold CV with L1 penalty;\n",
    "- use LogisticRegression() to learn the best model for the best C with L1 penalty on the entire training set\n",
    "\n",
    "Note: not all the solvers in LogisticRegressionCV() and LogisticRegression() can be used for L1 regularization! See the documentation and choose an appropriate solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the model using LogisticRegressionCV passing an appropriate solver, cv value, and choice of penalty\n",
    "regL1 = ????\n",
    "\n",
    "#fit the model on training data\n",
    "????\n",
    "\n",
    "#print the best C\n",
    "print ????\n",
    "\n",
    "\n",
    "#define the model using the best C and an appropriate solver\n",
    "regL1_final = ????\n",
    "\n",
    "#fit the model using the best C on the entire training set\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: plot the coefficients from logistic regression and the regularized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print the coefficients from logistic regression\n",
    "print ????\n",
    "\n",
    "#print the coefficients from L2 regularized logistic regression\n",
    "print ????\n",
    "\n",
    "#print the coefficients from L1 regularized logistic regression\n",
    "print ????\n",
    "\n",
    "# Plot the coefficients\n",
    "regL1_final_coef = regL1_final.coef_.reshape(regL1_final.coef_.shape[1],)\n",
    "\n",
    "ind = np.arange(1,len(reg_coef)+1)  # the x locations for the groups\n",
    "width = 0.25       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, reg_coef, width, color='r')\n",
    "rects2 = ax.bar(ind + width, regL2_final_coef, width, color='y')\n",
    "rects3 = ax.bar(ind + 2*width, regL1_final_coef, width, color='g')\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Log Regr', 'Log Regr + L2 Regul', 'Log Regr + L1 Regul'))\n",
    "plt.xlabel('Coefficient Idx')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients: Standard, Regularized L2 and L1 Version')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 11: how do the coefficients from L1 regularization compare to the ones from logistic regression and to the ones from L2 regularization? (max 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 12: obtain classification accuracy on training and test data for the best L1 regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now get training and test error and print training and test accuracy\n",
    "\n",
    "# predictions on training data \n",
    "Yhat_tr_LR_L1 = ????\n",
    "\n",
    "# predictions on test data \n",
    "Yhat_test_LR_L1 = ????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn on training data\n",
    "print \"Training Accuracy:\", 100*????\n",
    "\n",
    "# compute accuracy as suggested above using metrics.accuracy_score from scikit-learn on test data\n",
    "print \"Test Accuracy:\",100*????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 13: how does accuracy compare to logistic regression and to L2 regularization? (max 5 lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 14: use different data size\n",
    "\n",
    "Perform the same estimation procedures using different more points on the training data, that is fix Ntr = 100. You can simply copy and paste the code above into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put in this cell the code to do the same analysis as before but with Ntr=100\n",
    "\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 15: how do the results change with Ntr=100? (max 10 lines)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
